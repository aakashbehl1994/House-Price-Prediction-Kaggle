## Introduction
Kaggle describes this competition as follows:

Ask a home buyer to describe their dream house, and they probably won’t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition’s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.

With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

### Practice Skills
Creative feature engineering
Advanced regression techniques like random forest and gradient boosting

### Flow of Approach
Importing Dependencies
Loading and Inspecting Dataset
Data Cleaning
Preparing the Data
Feature Creation
Feature Scaling
Encoding Categorical variables
Regression Model Creation
Model optimization

### Different Models Used:
RandomForestRegressor
RandomForestRegressor(Grid Search)
SupportVectorRegressor
# Currently Adding More models to achive highest accuracy

## References

https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda

https://brownmath.com/stat/shape.htm

https://www.youtube.com/watch?v=XdM6ER7zTLk
